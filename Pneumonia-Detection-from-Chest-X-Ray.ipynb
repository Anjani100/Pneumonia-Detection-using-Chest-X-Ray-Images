{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, cv2, pickle, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATADIR = \"D:\\\\Dataset\\\\chest_xray\\\\train\"\n",
    "CATEGORIES = ['PNEUMONIA', 'NORMAL']\n",
    "IMG_SIZE = 200\n",
    "training_data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img = os.path.join(path, img)\n",
    "            img_array = cv2.imread(img)\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            training_data.append([new_array, class_num])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "random.shuffle(training_data)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for feature, label in training_data:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out_X = open('X_orig.pickle', 'wb')\n",
    "pickle.dump(X, pickle_out_X)\n",
    "pickle_out_X.close()\n",
    "\n",
    "pickle_out_y = open('y_orig.pickle', 'wb')\n",
    "pickle.dump(y, pickle_out_y)\n",
    "pickle_out_y.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n",
      "(624, 200, 200, 3) (624,)\n"
     ]
    }
   ],
   "source": [
    "# Creating Test Dataset\n",
    "\n",
    "import numpy as np\n",
    "import os, cv2, pickle, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATADIR = \"D:\\\\Dataset\\\\chest_xray\\\\test\"\n",
    "CATEGORIES = ['PNEUMONIA', 'NORMAL']\n",
    "IMG_SIZE = 200\n",
    "test_data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img = os.path.join(path, img)\n",
    "            img_array = cv2.imread(img)\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            test_data.append([new_array, class_num])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "random.shuffle(test_data)\n",
    "print(len(test_data))\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in test_data:\n",
    "    X_test.append(feature)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8896 samples, validate on 522 samples\n",
      "Epoch 1/25\n",
      "8896/8896 [==============================] - 18s 2ms/step - loss: 0.3918 - acc: 0.8182 - val_loss: 3.0359 - val_acc: 0.8084\n",
      "Epoch 2/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.1980 - acc: 0.9250 - val_loss: 3.6152 - val_acc: 0.7739\n",
      "Epoch 3/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.1552 - acc: 0.9445 - val_loss: 3.5566 - val_acc: 0.7778\n",
      "Epoch 4/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.1391 - acc: 0.9490 - val_loss: 2.8702 - val_acc: 0.8218\n",
      "Epoch 5/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.1131 - acc: 0.9578 - val_loss: 2.4010 - val_acc: 0.8506\n",
      "Epoch 6/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.1017 - acc: 0.9621 - val_loss: 3.4702 - val_acc: 0.7835\n",
      "Epoch 7/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0916 - acc: 0.9647 - val_loss: 2.9320 - val_acc: 0.8180\n",
      "Epoch 8/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0867 - acc: 0.9696 - val_loss: 3.3653 - val_acc: 0.7912\n",
      "Epoch 9/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0769 - acc: 0.9737 - val_loss: 3.1568 - val_acc: 0.8027\n",
      "Epoch 10/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0678 - acc: 0.9761 - val_loss: 3.3753 - val_acc: 0.7893\n",
      "Epoch 11/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0591 - acc: 0.9797 - val_loss: 3.3354 - val_acc: 0.7912\n",
      "Epoch 12/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0567 - acc: 0.9807 - val_loss: 2.9025 - val_acc: 0.8199\n",
      "Epoch 13/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0474 - acc: 0.9826 - val_loss: 3.2730 - val_acc: 0.7969\n",
      "Epoch 14/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0437 - acc: 0.9850 - val_loss: 3.1126 - val_acc: 0.8046\n",
      "Epoch 15/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0455 - acc: 0.9829 - val_loss: 3.3390 - val_acc: 0.7912\n",
      "Epoch 16/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0414 - acc: 0.9858 - val_loss: 3.0623 - val_acc: 0.8084\n",
      "Epoch 17/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0318 - acc: 0.9899 - val_loss: 3.7671 - val_acc: 0.7663\n",
      "Epoch 18/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0240 - acc: 0.9925 - val_loss: 3.9026 - val_acc: 0.7548\n",
      "Epoch 19/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0308 - acc: 0.9890 - val_loss: 3.0053 - val_acc: 0.8123\n",
      "Epoch 20/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0245 - acc: 0.9917 - val_loss: 4.1265 - val_acc: 0.7433\n",
      "Epoch 21/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0178 - acc: 0.9945 - val_loss: 3.4888 - val_acc: 0.7835\n",
      "Epoch 22/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0112 - acc: 0.9967 - val_loss: 3.3724 - val_acc: 0.7893\n",
      "Epoch 23/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 3.4339 - val_acc: 0.7854\n",
      "Epoch 24/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0113 - acc: 0.9958 - val_loss: 3.4414 - val_acc: 0.7854\n",
      "Epoch 25/25\n",
      "8896/8896 [==============================] - 17s 2ms/step - loss: 0.0088 - acc: 0.9978 - val_loss: 2.6419 - val_acc: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148f1b7d8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "pickle_in = open('X.pickle', 'rb')\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open('y.pickle', 'rb')\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = define_model()\n",
    "model.fit(X, y, batch_size = 32, epochs = 25, validation_data = (X_test[:522], y_test[:522]), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)  # evaluate the out of sample data with model\n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc)  # model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "pickle_in = open('X_orig.pickle', 'rb')\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open('y_orig.pickle', 'rb')\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(200, 200, 3))\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = define_model()\n",
    "model.fit(X, y, batch_size = 32, epochs = 5, validation_split = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda Navigator\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda Navigator\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda Navigator\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda Navigator\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda Navigator\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda Navigator\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4694/4694 [==============================] - 12s 3ms/step - loss: 0.3015 - acc: 0.8775\n",
      "Epoch 2/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1382 - acc: 0.9478\n",
      "Epoch 3/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1138 - acc: 0.9582\n",
      "Accuracy: 0.9559386968612671\n",
      "Epoch 1/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.3200 - acc: 0.8671\n",
      "Epoch 2/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1469 - acc: 0.9431\n",
      "Epoch 3/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1111 - acc: 0.9555\n",
      "Accuracy: 0.9080459765547537\n",
      "Epoch 1/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.3513 - acc: 0.8409\n",
      "Epoch 2/3\n",
      "4694/4694 [==============================] - 8s 2ms/step - loss: 0.1594 - acc: 0.9350\n",
      "Epoch 3/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1036 - acc: 0.9574\n",
      "Accuracy: 0.9712643680444623\n",
      "Epoch 1/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.4140 - acc: 0.8157\n",
      "Epoch 2/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1851 - acc: 0.9310\n",
      "Epoch 3/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1207 - acc: 0.9559\n",
      "Accuracy: 0.9406130263631828\n",
      "Epoch 1/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.3048 - acc: 0.8773\n",
      "Epoch 2/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1379 - acc: 0.9450\n",
      "Epoch 3/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.0910 - acc: 0.9661\n",
      "Accuracy: 0.9655172413793104\n",
      "Epoch 1/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.3369 - acc: 0.8455\n",
      "Epoch 2/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.1214 - acc: 0.9553A: 0s - loss: 0.1241 - a\n",
      "Epoch 3/3\n",
      "4694/4694 [==============================] - 9s 2ms/step - loss: 0.0923 - acc: 0.9668\n",
      "Accuracy: 0.9693486585470908\n",
      "Epoch 1/3\n",
      "4695/4695 [==============================] - 10s 2ms/step - loss: 0.3403 - acc: 0.8543\n",
      "Epoch 2/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1383 - acc: 0.9478\n",
      "Epoch 3/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1001 - acc: 0.9634\n",
      "Accuracy: 0.9520153552007766\n",
      "Epoch 1/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.3292 - acc: 0.8556\n",
      "Epoch 2/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1646 - acc: 0.9348\n",
      "Epoch 3/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1076 - acc: 0.9583\n",
      "Accuracy: 0.9692898273696826\n",
      "Epoch 1/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.3314 - acc: 0.8562A: 0s - loss: 0.3295 - acc: 0.\n",
      "Epoch 2/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1515 - acc: 0.9404\n",
      "Epoch 3/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1155 - acc: 0.9527\n",
      "Accuracy: 0.9347408829174664\n",
      "Epoch 1/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.3892 - acc: 0.8315\n",
      "Epoch 2/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1625 - acc: 0.9338\n",
      "Epoch 3/3\n",
      "4695/4695 [==============================] - 9s 2ms/step - loss: 0.1114 - acc: 0.9574\n",
      "Accuracy: 0.9366602687140115\n",
      "Avg. Accuracy: 0.9503434301952003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pickle_in = open('X_orig.pickle', 'rb')\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open('y_orig.pickle', 'rb')\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = define_model()\n",
    "    model.fit(X[train], y[train], batch_size = 32, epochs = 3, shuffle = True)\n",
    "    _, score = model.evaluate(X[test], y[test], verbose = 0)\n",
    "    print('Accuracy:', score)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Avg. Accuracy:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
